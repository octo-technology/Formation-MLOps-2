
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>TP4 - Orchestration</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="tp4"
                  title="TP4 - Orchestration"
                  environment="web"
                  feedback-link="https://gitlab.com/octo-technology/les-bg-de-la-data/s-s-all/formation/dsin2/-/issues/new">
    
      <google-codelab-step label="Overview" duration="60">
        <h2 is-upgraded>A l&#39;issue de cette section, vous aurez découvert</h2>
<ul>
<li>Découvrir l&#39;orchestration avec Airflow,</li>
<li>Savoir créer un <code>DAG</code> et les scheduler,</li>
<li>Savoir créer des <code>tasks</code> Airflow et les orchestrer,</li>
<li>Comprendre la gestion des <code>IO</code> avec Airflow.</li>
</ul>
<h2 is-upgraded>Présentation des nouveautés sur la branche de ce TP</h2>
<p>Pour ce TP, utiliser la branch 4_starting_orchestration</p>
<p><code>git checkout 4_starting_orchestration</code></p>
<p>Sur cette branche, il y a maintenant :</p>
<ul>
<li>Un DAG <code>dags/train.py</code> qui permet d&#39;entraîner un modèle</li>
<li>Un DAG <code>dags/predict.py</code> qui est incomplet et qui permettra de réaliser des prédictions</li>
<li>Les fonctions existantes dans <code>formation_indus_avancee/</code> ont été décoré avec des <code>read</code> et des <code>write</code> pour donner des fonctions <code>function_name_with_io</code></li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Scripts à disposition" duration="0">
        <p>Le dossier <code>dsin2/scripts</code> contient des scripts d&#39;entraînement et de prédiction pour notre cas d&#39;usage de Machine Learning.</p>
<p>Nous allons désormais voir comment orchestrer ces tâches grâce à <code>Airflow</code>.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Revue de code avec les formateurs" duration="0">
        <p>Revue de code avec les formateurs pour introduire les concepts de DAGs et de tâches dans le code.</p>
<h2 is-upgraded>Gestion des IO</h2>
<p>Il n&#39;est pas conseillé de passer de la donnée d&#39;une tâche à l&#39;autre dans un DAG Airflow.</p>
<p>Pour répondre à ce problème, nous avons décoré la fonction de prédiction avec</p>
<ul>
<li>une fonction permettant de lire un fichier en entrée,</li>
<li>et d&#39;écrire le résultat de la tâche dans un fichier en sortie.</li>
</ul>
<p>A l&#39;image des fonctions <code>train_with_io</code> et <code>train</code> du module <code>train_and_predict.py</code> dans <code>/formation_indus_ds_avancee</code>, nous avons créé une fonction <code>predict_with_io</code> qui soit utilisable par le DAG Airflow.</p>
<p>Les prédictions réalisées sont écrites dans 2 fichiers identiques:</p>
<ul>
<li>{date}.csv où la date est au format <code>%Y%m%d-%H%M%S</code>, exemple:</li>
<li>latest.csv</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Démarrer avec Airflow" duration="0">
        <ul>
<li>Modifier le fichier <code>/airflow/airflow.cfg</code> avec l&#39;éditeur <code>nano /airflow/airflow.cfg</code>:  <ul>
<li>Changer la variable <code>dags_folder</code> pour pointer sur <code>/home/jovyan/dsin2/dags</code>, cela permet d&#39;indiquer à airflow où se situent vos DAGs</li>
<li>Changer la variable <code>load_examples</code> à <code>False</code>, cela permet d&#39;éviter que airflow chargent les DAGs d&#39;exemples.</li>
<li>Changer la variable <code>dag_dir_list_interval</code> à <code>5</code>, cela permet de rafraichir les DAGs toutes les 5 secondes au lieu de toutes les 5 minutes (ce qui est pratique en phase de développement).</li>
</ul>
</li>
</ul>
<pre><code language="language-toml" class="language-toml"># Fichier /airflow/airflow.cfg
[core]
# The folder where your airflow pipelines live, most likely a
# subfolder in a code repository
# This path must be absolute
dags_folder = /airflow/dags

...

# Whether to load the examples that ship with Airflow.
load_examples = True

...

# How often (in seconds) to scan the DAGs directory for new files. Default to 5 minutes.
dag_dir_list_interval = 300
</code></pre>
<ul>
<li>Dans le <code>Launcher</code>, lancer le service <code>Airflow</code>.</li>
</ul>
<p class="image-container"><img alt="launcher" src="img/dbc63491bde0fa9c.png"></p>
<p>L&#39;interface graphique d&#39;Airflow devrait s&#39;ouvrir dans un nouveau onglet.</p>
<ul>
<li>En ligne de commande dans un terminal que vous ne devez pas fermer, lancer le scheduler avec <code>airflow scheduler</code>.</li>
</ul>
<p>L&#39;interface graphique devrait désormais afficher 3 dags:</p>
<p class="image-container"><img alt="ui-airflow" src="img/9d180270c937df3b.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="Lancer un premier DAG d&#39;entraînement" duration="0">
        <p>Afin de s&#39;entraîner, il va nous falloir des données d&#39;entraînement !</p>
<p>Elles ne sont pas versionnées dans ce repo. Télécharger les données avec la commande <code>make dataset</code>.</p>
<p>Les données sont désormais disponible dans <code>dsin2/data/la-haute-borne-data-2017-2020.csv</code>.</p>
<p>Airflow tourne en utilisant l&#39;env <code>base</code> de python. Il faut donc installer notre librairie</p>
<ul>
<li>Installer le package en ouvrant un nouveau terminal, <code>cd dsin2; pip install .</code></li>
</ul>
<p>Pour lancer le dag <code>train</code>:</p>
<ul>
<li>activer le DAG en appuyant sur le bouton <code>ON/OFF</code> (à gauche),</li>
<li>déclencher le DAG manuellement en cliquant sur <code>Trigger Dag</code> dans les links (l&#39;icône play)  (sur la droite).</li>
</ul>
<p class="image-container"><img alt="ui-airflow" src="img/9d180270c937df3b.png"></p>
<p>Inspecter le dag <code>train</code> en cliquant sur celui-ci, la tâche <code>prepare_features</code> devrait avoir commencé:</p>
<p class="image-container"><img alt="train-dag" src="img/e3a972a23a9c3a1d.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="DAG de prédiction" duration="0">
        <p>Compléter le DAG <code>dags/predict</code> pour intégrer la fonction <code>predict_with_io</code> dans un opérateur, avec les bons arguments.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Pour aller plus loin" duration="0">
        <p>Pour aller plus loin en attendant les autres formés vous pouvez regarder comment utiliser les fichiers géénrés par le dag <code>get_data_from_engie_hub.py</code> dans le dag <code>predict</code>.</p>
<p>Il s&#39;agit de</p>
<ul>
<li>créer une nouvelle fonction qui permet de faire le prepare feature sur le dernier fichier généré.</li>
<li>appeler cette fonction dans le DAG de predict en lui passant le dossier de fichier généré.</li>
</ul>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/codelab-elements/native-shim.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/prettify.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>
