
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>TP7 - Exposition de modèles</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-49880327-14"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="tp7"
                  title="TP7 - Exposition de modèles"
                  environment="web"
                  feedback-link="https://gitlab.com/octo-technology/les-bg-de-la-data/s-s-all/formation/dsin2/-/issues/new">
    
      <google-codelab-step label="Overview" duration="30">
        <h2 is-upgraded>A l&#39;issue de cette section, vous aurez découvert</h2>
<ul>
<li>Comment fonctionne une simple API Flask,</li>
<li>Le pattern d&#39;exposition <code>embedded model</code>,</li>
<li>Le pattern d&#39;exposition <code>model as a service</code>,</li>
<li>Le pattern d&#39;exposition <code>model published as data</code>,</li>
</ul>
<h2 is-upgraded>Présentation des nouveautés sur la branche de ce TP</h2>
<p>Pour ce TP, utiliser la branch 7_starting_exposition</p>
<p><code>git checkout 7_starting_exposition</code></p>
<p>Sur cette branche, il y a maintenant :</p>
<ul>
<li>Un dossier exposition qui contient trois format d&#39;expositions</li>
<li><code>embedded_model</code> une app streamlit qui permet de demander des prédictions</li>
<li><code>exposing_predictions</code> une app streamlit qui permet de voir les prédictions réalisées précédement</li>
<li><code>model_as_a_service</code> une api flask qui permet de demander des prédictions</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Développement d&#39;API avec Flask" duration="0">
        <p>Flask est un microserveur d&#39;application. Il est souvent utilisé en Python pour développer des APIs et exposer des ressources.</p>
<h2 is-upgraded>Exposition &#34;model as a service&#34;</h2>
<ul>
<li>Se rendre dans <code>dsin2-public-ocac/exposition/model_as_a_service/</code></li>
<li>Démarrer le serveur Flask d&#39;exposition avec <code>FLASK_APP=inference.py python -m flask run</code></li>
</ul>
<p>Le serveur d&#39;exposition est désormais disponible sur le port 5000 <a href="http://localhost:5000" target="_blank">http://localhost:5000</a>, avec:</p>
<ul>
<li>la route de healthcheck <code>/health</code> pour vérifier que le service est fonctionnel,</li>
<li>la route <code>/predict</code> pour demander une prédiction  <ul>
<li>Il est possible de demander une prédiction en spécifiant une valeur pour la feature explicative <code>Ws1_avg</code></li>
</ul>
</li>
</ul>
<p class="image-container"><img alt="requete-healthcheck" src="img/47019fb2df4999bd.png"></p>
<p>⚠ Le serveur Flask ne sera pas consultable dans votre navigateur !</p>
<p>Dans votre terminal, avec l&#39;outil en ligne de commande <code>cURL</code>, réalisez les requêtes HTTP suivantes:</p>
<ul>
<li>explorez le code de l&#39;API Flask dans <code>dsin2/exposition/model_as_a_service/inference.py</code>,</li>
<li>requêtez l&#39;url de <code>healthcheck</code> du service pour s&#39;assurer qu&#39;il fonctionne (<a href="http://localhost:5000/health" target="_blank">http://localhost:5000/health</a>),</li>
<li>requêtez une prédiction sur <a href="http://localhost:5000/predict" target="_blank">http://localhost:5000/predict</a>,</li>
<li>requêtez une prédiction pour une <code>Wind Speed</code> de 0, 10, 50, 100.</li>
</ul>
<p>Pour spécifier une valeur de <code>Wind Speed</code> il faut ajouter <code>?Ws1_avg=<Your value></code> à l&#39;adresse</p>


      </google-codelab-step>
    
      <google-codelab-step label="Démo: Exposition | model as a service" duration="0">
        <p>La manipulation sera faite par les formateurs</p>
<p>Dans le dossier <code>exposition/</code> se trouvent un fichier <code>docker-compose.yaml</code>, exécutable avec <code>docker-compose up</code>.</p>
<p>Une fois lancée, l&#39;application streamlit est accessible sur <a href="http://localhost:8092" target="_blank">http://localhost:8092</a> et le service Flask est disponible sur <a href="http://localhost:5000/health" target="_blank">http://localhost:5000/health</a>.</p>
<p>Dans le dossier <code>exposition/model_as_a_service/</code> se trouve la définition de ces 2 services:</p>
<ul>
<li>une application de dashboarding construite avec Streamlit dans <code>app.py</code>,</li>
<li>un service d&#39;inférence construit avec Flask dans <code>inference.py</code>.</li>
</ul>
<p>L&#39;application streamlit permet d&#39;afficher une prédiction à la demande selon la valeur de <code>Ws1_avg</code> spécifiée par l&#39;utilisateur.</p>
<p class="image-container"><img alt="streamlit-model-as-a-service" src="img/928fca2a95c4af66.png"></p>
<ul>
<li>Modifier la valeur de <code>Wind Speed Average</code> à 0, 10, 20, 50, 100 et demander une prédiction</li>
<li>Observer les logs de docker-compose, et constater que le service Flask réalise les prédictions quand Streamlit les demande.</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Démo: Exposition | embedded model" duration="0">
        <p>La manipulation sera faite par les formateurs</p>
<p>Dans le dossier <code>exposition/</code> se trouvent un fichier <code>docker-compose.yaml</code>, exécutable avec <code>docker-compose up</code>.</p>
<p>Une fois lancée, l&#39;application streamlit avec modèle embarqué est accessible sur <a href="http://localhost:8091" target="_blank">http://localhost:8091</a>.</p>
<p>Dans le dossier <code>exposition/embedded_model/</code> se trouve la définition de ce service de dashboarding:</p>
<ul>
<li>une application de dashboarding construite avec Streamlit dans <code>embedded_model.py</code>,</li>
<li>il n&#39;y a pas de service d&#39;inférence.</li>
</ul>
<p>L&#39;application streamlit permet d&#39;afficher une prédiction à la demande selon la valeur de <code>Ws1_avg</code> spécifiée par l&#39;utilisateur.</p>
<p class="image-container"><img alt="streamlit-embedded-model" src="img/9307b3eae10f0523.png"></p>
<ul>
<li>Modifier la valeur de <code>Wind Speed Average</code> à 0, 10, 20, 50, 100 et demander une prédiction</li>
<li>Observer les logs de docker-compose, et constater que le service Flask ne réalise pas de prédictions quand Streamlit les demande.</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Démo: Exposition | Exposing predictions" duration="0">
        <p>La manipulation sera faite par les formateurs</p>
<p>Dans le dossier <code>exposition/</code> se trouvent un fichier <code>docker-compose.yaml</code>, exécutable avec <code>docker-compose up</code>.</p>
<p>Une fois lancée, l&#39;application streamlit est accessible sur <a href="http://localhost:8090" target="_blank">http://localhost:8090</a>.</p>
<p>Dans le dossier <code>exposition/exposing_predictions/</code> se trouve la définition de ce service de dashboarding dans <code>display_predictions.py</code>.</p>
<p>L&#39;application streamlit affiche des prédictions déjà réalisées.</p>
<p class="image-container"><img alt="streamlit-exposing-predictions" src="img/9ec456f8fcd6c1e3.png"></p>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/codelab-elements/native-shim.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/prettify.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/codelab-elements.js"></script>
  <script src="//support.google.com/inapp/api.js"></script>

</body>
</html>
